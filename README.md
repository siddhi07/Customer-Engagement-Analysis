Customer Engagement Analysis â€“ AMEX Offer Recommendation System

This project builds a customer engagement and offer recommendation system using transaction behavior, event interactions, and offer metadata.
The goal is to predict whether a customer will engage (click) with a given offer, and to rank offers per customer using machine learning models.

The project is designed as a modular, reproducible ML pipeline, starting from raw Parquet data and ending with trained models and submission files.

ğŸ“‚ Why the Raw Data Is Not in This Repository

The original dataset consists of large Parquet files (several GBs), which are not suitable for GitHub.

Therefore:

âŒ Raw Parquet files are excluded from this repository

âœ… The repository contains:

ETL scripts

Feature engineering code

Model training pipelines

Instructions to regenerate all intermediate files

This follows industry best practices for ML repositories.

ğŸ§  End-to-End Data Pipeline
Raw Parquet Data
   â†“
read.py
   â†’ train_features.csv
   â†’ test_features.csv
   â†“
ETL / Feature Engineering
   â†“
amex_offer_train.py  (main ML pipeline)
OR
etl_round2.py / model.py (baseline & ranking models)
   â†“
submission.csv / amex_pipeline.pkl

##ğŸ“ Repository Structure

â”œâ”€â”€ read.py                  # Converts raw Parquet files into feature CSVs

â”œâ”€â”€ etl_round2.py            # Feature selection + ranking model (LightGBM)

â”œâ”€â”€ amex_offer_train.py      # Main ML pipeline (LightGBM + XGBoost ensemble)

â”œâ”€â”€ model.py                 # Baseline RandomForest model + submission

â”œâ”€â”€ data_dictionary.csv      # Column definitions

â”œâ”€â”€ README.md

â””â”€â”€ .gitignore               # Excludes Parquet & large data files

ğŸ”„ Step-by-Step Pipeline Explanation
1ï¸âƒ£ read.py â€” Raw Data â†’ Feature CSVs

Purpose:
Transforms raw Parquet data into model-ready CSV files.

Inputs (NOT included in GitHub):

train_data.parquet

test_data.parquet

add_event.parquet

add_trans.parquet

offer_metadata.parquet

Key Operations:

Data type normalization

Offer metadata joins

Event-based interaction features

RFM features:

Recency

Frequency

Monetary value

Outputs:

train_features.csv

test_features.csv

python read.py

2ï¸âƒ£ Feature Engineering & Modeling Options

You can proceed with either of the following paths.

ğŸ”¹ Option A: amex_offer_train.py (Main Production Pipeline)

Purpose:
End-to-end ML pipeline for high-quality predictions.

Key Features:

Advanced feature engineering

Datetime feature extraction

Transaction aggregations

Ensemble of:

LightGBM

XGBoost

Outputs:

amex_pipeline.pkl â†’ saved trained pipeline

Validation metrics (LogLoss)

python amex_offer_train.py

ğŸ”¹ Option B: etl_round2.py + model.py (Baselines & Ranking)
etl_round2.py

Performs:

Label encoding

Variance thresholding

GroupKFold splitting (by customer)

Trains a LightGBM LambdaRank model

Outputs:

submission.csv

python etl_round2.py

model.py

Trains a RandomForest baseline

Adds:

CTR per user

CTR per offer

Outputs:

submission.csv

python model.py

ğŸ“¤ Final Outputs
File	Description
train_features.csv	Engineered training features
test_features.csv	Engineered test features
submission.csv	Final predictions
amex_pipeline.pkl	Serialized trained model pipeline
ğŸ› ï¸ Requirements

Install dependencies using:

pip install pandas numpy scikit-learn lightgbm xgboost catboost joblib

ğŸš€ Key Highlights

Scalable ETL design

Customer-aware modeling (prevents data leakage)

Ranking + classification approaches

Production-ready pipeline saving

GitHub-friendly structure (no large data committed)

ğŸ“Œ Notes

To fully reproduce results, place the raw Parquet files in the project root before running read.py

Sample data can be used for testing if full data is unavailable

All scripts are modular and can be run independently
